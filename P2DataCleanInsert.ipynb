{
 "metadata": {
  "name": "",
  "signature": "sha256:bd077ce87d5c58f0528f787ceb1d896db7f6cede3e0566e234c1aff8b6fbe1dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 1\n",
      "import xml.etree.cElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "import codecs\n",
      "import json\n",
      "import pymongo\n",
      "from pymongo import MongoClient\n",
      "\n",
      "#Mongodb instance initiation, make sure Mongodb is running on 27017 (default)\n",
      "client = MongoClient('localhost', 27017)\n",
      "db = client.mydb\n",
      "collection = db.austin_texas\n",
      "\n",
      "#osm file name to be processed and cleaned uncomment for the sample\n",
      "OSMFILE = 'austin_texas.osm'\n",
      "#OSMFILE = 'austin_texas_sample.osm'\n",
      "\n",
      "#Regex for streetname and other searching and matching needs for cleaning\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
      "zip_re = re.compile(r'[0-9]{5}')\n",
      "\n",
      "#Formatting for the creation information contained in each node or way\n",
      "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
      "\n",
      "#Full street name abbreviation transformation/fix specific to Austin data\n",
      "mappingFull = { \"St\": \"Street\",\n",
      "            \"St.\": \"Street\",\n",
      "            \"Ave\": \"Avenue\",\n",
      "            \"Rd.\": 'Road',\n",
      "            \"Ave.\": \"Avenue\",\n",
      "            \"Blvd\": \"Boulevard\",\n",
      "            \"Blvd.\": \"Boulevard\",\n",
      "            \"CR\": \"Circle\",\n",
      "            \"Cir\": \"Circle\",\n",
      "            \"Ct\": \"Court\",\n",
      "            \"Cv\": \"Cove\",\n",
      "            \"Dr\": \"Drive\",\n",
      "            \"Dr.\": \"Drive\",\n",
      "            \"Expwy\": \"Expressway\",\n",
      "            \"Hwy\": \"Highway\",\n",
      "            \"Ln\": \"Lane\",\n",
      "            \"N\": \"North\",\n",
      "            \"Pkwy\": \"Parkway\",\n",
      "            \"RD\": \"Road\",\n",
      "            \"Rd\": \"Road\",\n",
      "            \"W\": \"West\",\n",
      "            \"WEST\": \"West\",\n",
      "            \"lane\": \"Lane\",\n",
      "            \"street\": \"Street\",\n",
      "            \"Bld\": \"Building\",\n",
      "            \"Bldg\": \"Building\",\n",
      "            \"Bldg.\": \"Building\",\n",
      "            \"st\": \"Street\",\n",
      "            \"Blvd,\": \"Boulevard,\",\n",
      "            \"Crongress\": \"Congress\",\n",
      "            \"E\": \"East\",\n",
      "            \"E.\": \"East\",\n",
      "            \"Expwy\": \"Expressway\",\n",
      "            \"F.M.\": \"FM\",\n",
      "            \"FM1431\": \"FM 1431\",\n",
      "            \"HWY\": \"Highway\",\n",
      "            \"I35\": \"Interstate Highway 35\",\n",
      "            \"IH\": \"Interstate Highway\",\n",
      "            \"IH-35\": \"Interstate Highway 35\",\n",
      "            \"IH35\": \"Interstate Highway 35\",\n",
      "            \"MCNEIL\": \"McNeil\",\n",
      "            \"Mo-Pac\": \"MoPac\",\n",
      "            \"Mopac\": \"MoPac\",\n",
      "            \"N\": \"North\",\n",
      "            \"N.\": \"North\",\n",
      "            \"Of\": \"of\",\n",
      "            \"texas\": \"Texas\",\n",
      "            \"Pkwy,\": \"Parkway,\",\n",
      "            \"STE\": \"Suite\",\n",
      "            \"Ste\": \"Suite\",\n",
      "            \"Ste.\": \"Suite\",\n",
      "            \"S\": \"South:\",\n",
      "            \"U.S.\": \"US\",\n",
      "            \"W,\": \"West,\",\n",
      "            \"W.\": \"West\",\n",
      "            \"WEST\": \"West\",\n",
      "            \"brigadoon\": \"Brigadoon\",\n",
      "            \"church\": \"Church\",\n",
      "            \"goforth\": \"Goforth\",\n",
      "            \"lane\": \"Lane\",\n",
      "            \"main\": \"Main\",\n",
      "            \"south\": \"South\",\n",
      "            \"st\": \"Street\",\n",
      "            \"street\": \"Street\",\n",
      "            \"west\": \"West\",\n",
      "            \"To\": \"to\"\n",
      "            }\n",
      "\n",
      "#Tag matching functions\n",
      "def is_street_name(elem):\n",
      "    #make sure that it's the streetname field-\n",
      "    return (elem.attrib['k'] == \"addr:street\")\n",
      "\n",
      "def is_state(elem):\n",
      "    return (elem.attrib['k'] == \"addr:state\")\n",
      "\n",
      "def is_zip(elem):\n",
      "    return (elem.attrib['k'] == \"addr:postcode\")\n",
      "\n",
      "def is_city(elem):\n",
      "    return (elem.attrib['k'] == \"addr:city\")\n",
      "\n",
      "\n",
      "#def update_name(name, mapping):\n",
      "    #gives more consistency to the street names \n",
      "    #m = street_type_re.search(name)\n",
      "    #if m:\n",
      "    #    if mapping.has_key(m.group()):\n",
      "    #        name = name.replace(m.group(),mapping[m.group()])\n",
      "    #return name\n",
      "\n",
      "#Full street name transformation function\n",
      "def update_name_Full(name, mappingFull):\n",
      "    #gives more consitency to street naming convention after auditing the data separately\n",
      "    name_split = name.strip().split(' ')\n",
      "    \n",
      "    ndx = 0\n",
      "    for i in name_split:\n",
      "        if mappingFull.has_key(i):\n",
      "            name_split[ndx] = mappingFull[i]\n",
      "        ndx += 1\n",
      "    \n",
      "    name_join = ' '.join(name_split)\n",
      "    return name_join\n",
      "\n",
      "#Update zipcode strips entries to the 5 digit zipcode only\n",
      "def update_zip(zipcode):\n",
      "    m = zip_re.search(zipcode)\n",
      "    if m:\n",
      "        #special audited case, 14150 is a street number\n",
      "        if m == \"14150\":\n",
      "            return \"76574\"\n",
      "        return m.group()\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "#Update city name, removes state information, fixes misspellings, captialization\n",
      "def update_city(city):\n",
      "    city = city.lower().replace(', tx', '')\n",
      "    \n",
      "    city_split = city.strip().split(' ')\n",
      "    if len(city_split) == 1:\n",
      "        city_split = city_split[0].split(';')\n",
      "        city_fix = city_split[0].capitalize()\n",
      "    else:\n",
      "        city_split = [i.capitalize() for i in city_split]\n",
      "        city_fix = ' '.join(city_split)\n",
      "    \n",
      "    if city_fix == \"Westlake Hills\":\n",
      "        city_fix = \"West Lake Hills\"\n",
      "    \n",
      "    return city_fix\n",
      "\n",
      "#Main processing function for each element, shapes each element and the tags it contains to json\n",
      "def shape_element(element):\n",
      "    node = {}\n",
      "    if element.tag == \"node\" or element.tag == \"way\" :\n",
      "    #if element.tag == \"way\":\n",
      "        attribDict = element.attrib\n",
      "        \n",
      "        #non-shared attributes of node and way----------------------\n",
      "        if element.tag == \"node\":\n",
      "            node['type'] = 'node'\n",
      "            node['pos'] = [float(attribDict['lat']), float(attribDict['lon'])]\n",
      "        elif element.tag == 'way':\n",
      "            node['type'] = 'way'\n",
      "            for tag in element.iter('nd'):\n",
      "                if not(node.has_key('node_refs')):\n",
      "                       node['node_refs'] = []\n",
      "                node['node_refs'].append(tag.attrib['ref'])\n",
      "                \n",
      "            \n",
      "        #shared attributes of node and way---------------------------\n",
      "        node['id'] = attribDict['id']\n",
      "        if attribDict.has_key('visible'):\n",
      "            node['visible'] = attribDict['visible']\n",
      "        else:\n",
      "            node['visible'] = 'false'\n",
      "        node['created'] = {}\n",
      "        for item in CREATED:\n",
      "            node['created'][item] = attribDict[item]\n",
      "        \n",
      "        #-------------------------------------------------------------\n",
      "        for tag in element.iter('tag'):\n",
      "            \n",
      "            if problemchars.search(tag.attrib['k']):\n",
      "                continue\n",
      "                \n",
      "            #process single world lower case tags---------------------------\n",
      "            elif lower.match(tag.attrib['k']):\n",
      "                if tag.attrib['k'] == \"amenity\":\n",
      "                    norm_field = tag.attrib['v'].lower().replace(' ','_')\n",
      "                    #if norm_field == 'yes':\n",
      "                    #    norm_field = 'health_and_well-being'\n",
      "                    node[tag.attrib['k']] = norm_field\n",
      "                elif tag.attrib['k'] == \"cuisine\":\n",
      "                    norm_field = tag.attrib['v'].lower().replace(' ','_')\n",
      "                    if norm_field == \"bar-b-q\" or norm_field == \"bbq\":\n",
      "                        norm_field = \"barbecue\"\n",
      "                    \n",
      "                    node[tag.attrib['k']] = norm_field\n",
      "                else:\n",
      "                    node[tag.attrib['k']] = tag.attrib['v']\n",
      "                    \n",
      "            #process tags with a \":\" in the middle-----------------------------\n",
      "            elif lower_colon.match(tag.attrib['k']):\n",
      "                if tag.attrib['k'][0:5] == 'addr:':\n",
      "                    addrSplit = tag.attrib['k'].strip().split(':')\n",
      "                    \n",
      "                    if not(node.has_key('address')):\n",
      "                        node['address'] = {}\n",
      "                    if is_street_name(tag):\n",
      "                        #node['address']['street'] = update_name(tag.attrib['v'], mapping)\n",
      "                        node['address']['street'] = update_name_Full(tag.attrib['v'], mappingFull)\n",
      "                    elif is_state(tag):\n",
      "                        node['address']['state'] = 'TX'\n",
      "                    elif is_city(tag):\n",
      "                        node['address']['city'] = update_city(tag.attrib['v'])\n",
      "                    elif is_zip(tag):\n",
      "                        m = update_zip(tag.attrib['v'])\n",
      "                        if m:\n",
      "                            node['address']['postcode'] = m\n",
      "                    else:\n",
      "                        node['address'][addrSplit[1]] = tag.attrib['v']\n",
      "                else:\n",
      "                    node[tag.attrib['k']] = tag.attrib['v']\n",
      "        #returns the formatted node dictionary to be inserted into mongodb----------------------------\n",
      "        return node\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "def process_map(file_in):\n",
      "    # Insert into Mongodb instance element by element\n",
      "    #file_out = \"{0}.json\".format(file_in)\n",
      "    i = 0\n",
      "    data = []\n",
      "    for _, element in ET.iterparse(file_in):\n",
      "        el = shape_element(element)\n",
      " \n",
      "        if el:\n",
      "            #commented out large json element formation for possible memory considerations, \n",
      "            #instead each node/way entry is inserted individually\n",
      "            #data.append(el)\n",
      "            i += 1\n",
      "            collection.insert(el)\n",
      "\n",
      "        #if i > 100:\n",
      "           #break\n",
      "\n",
      "    #returns data (json formated list of dictionaries) to be imported into mongodb, \n",
      "    return data, i\n",
      "\n",
      "\n",
      "def main():\n",
      "    data, count = process_map(OSMFILE)\n",
      "    #pprint.pprint(data[0:20])\n",
      "    print \"done... \" + str(count) + \" documents inserted\"\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 2\n",
      "#Execute Block 1, and insert into MongoDB instance\n",
      "main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done... 859061 documents inserted\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 3\n",
      "#Testcode, not manatory execution\n",
      "x = collection.find(({\"type\":\"way\"})).limit(1)\n",
      "for i in x:\n",
      "    pprint.pprint(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'_id': ObjectId('5519d7e8145603dc15cabcba'),\n",
        " u'bridge': u'yes',\n",
        " u'created': {u'changeset': u'10974544',\n",
        "              u'timestamp': u'2012-03-14T05:28:59Z',\n",
        "              u'uid': u'119881',\n",
        "              u'user': u'Clorox',\n",
        "              u'version': u'19'},\n",
        " u'highway': u'motorway',\n",
        " u'id': u'4358672',\n",
        " u'lanes': u'3',\n",
        " u'layer': u'1',\n",
        " u'node_refs': [u'26546039', u'1674200199'],\n",
        " u'old_ref': u'SH 29',\n",
        " u'oneway': u'yes',\n",
        " u'ref': u'US 183',\n",
        " u'toll': u'no',\n",
        " u'type': u'way',\n",
        " u'visible': u'false'}\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 4\n",
      "#User Statistics calculations\n",
      "#Change the limit to see different aggregated contribution statistics\n",
      "pipeline = [{\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}}, {\"$sort\": {\"count\": -1}},{\"$limit\": 3}]\n",
      "result = collection.aggregate(pipeline)\n",
      "pprint.pprint(result[\"result\"])\n",
      "\n",
      "total = 0\n",
      "for i in result[\"result\"]:\n",
      "    total += i[\"count\"]\n",
      "\n",
      "print \"Contributed: \", total\n",
      "print \"Percentage of Total: \", total/859061.*100\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'_id': u'woodpeck_fixbot', u'count': 243497},\n",
        " {u'_id': u'varmint', u'count': 38856},\n",
        " {u'_id': u'richlv', u'count': 37953}]\n",
        "Contributed:  320306\n",
        "Percentage of Total:  37.2855943874\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 5\n",
      "#Number of individuals with 1 posting\n",
      "pipeline = [{\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}}, \n",
      "            {\"$group\": {'_id': \"$count\", \"num\":{\"$sum\":1}}},\n",
      "            {\"$match\":{\"_id\": 1}},\n",
      "            {\"$limit\": 3}]\n",
      "result = collection.aggregate(pipeline)\n",
      "pprint.pprint(result[\"result\"])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'_id': 1, u'num': 169}]\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 6\n",
      "#Top List for amenity\n",
      "pipeline = [{\"$match\": {\"amenity\":{\"$exists\":1}}},\n",
      "            {\"$group\": {\"_id\": \"$amenity\", \"count\": {\"$sum\": 1}}}, \n",
      "            {\"$sort\": {\"count\": -1}},\n",
      "            {\"$limit\": 5}]\n",
      "result = collection.aggregate(pipeline)\n",
      "pprint.pprint(result[\"result\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'_id': u'parking', u'count': 1847},\n",
        " {u'_id': u'restaurant', u'count': 684},\n",
        " {u'_id': u'waste_basket', u'count': 591},\n",
        " {u'_id': u'school', u'count': 574},\n",
        " {u'_id': u'fast_food', u'count': 498}]\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Block 7\n",
      "#Top List for cuisine\n",
      "pipeline = [{\"$match\": {\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\"}},\n",
      "            {\"$group\": {\"_id\": \"$cuisine\", \"count\": {\"$sum\": 1}}}, \n",
      "            {\"$sort\": {\"count\": -1}},\n",
      "            {\"$limit\": 10}]\n",
      "result = collection.aggregate(pipeline)\n",
      "pprint.pprint(result[\"result\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'_id': None, u'count': 373},\n",
        " {u'_id': u'mexican', u'count': 68},\n",
        " {u'_id': u'american', u'count': 25},\n",
        " {u'_id': u'pizza', u'count': 23},\n",
        " {u'_id': u'chinese', u'count': 20},\n",
        " {u'_id': u'italian', u'count': 15},\n",
        " {u'_id': u'thai', u'count': 14},\n",
        " {u'_id': u'indian', u'count': 14},\n",
        " {u'_id': u'sandwich', u'count': 13},\n",
        " {u'_id': u'barbecue', u'count': 13}]\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}